{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Experiment 4 - Containerization with Docker (Simulated in Colab)\n", "This notebook trains a simple ML model, creates required files (`model.py`, `requirements.txt`, `Dockerfile`),\n", "and downloads them. Docker cannot run in Colab, but this simulates the steps for your lab record."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "from sklearn.ensemble import RandomForestClassifier\n", "import joblib\n", "\n", "# Load dataset\n", "iris = load_iris()\n", "X, y = iris.data, iris.target\n", "\n", "# Train model\n", "model = RandomForestClassifier(n_estimators=100, random_state=42)\n", "model.fit(X, y)\n", "\n", "# Save trained model\n", "joblib.dump(model, \"iris_model.pkl\")\n", "\n", "print(\"\u2705 Model trained and saved as iris_model.pkl\")\n", "print(\"Prediction for first 5 rows:\", model.predict(X[:5]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_code = \"\"\"\\\n", "import joblib\n", "from sklearn.datasets import load_iris\n", "\n", "print(\"Starting model.py ...\")\n", "\n", "# Load the trained model\n", "model = joblib.load(\"iris_model.pkl\")\n", "\n", "# Load dataset\n", "iris = load_iris()\n", "X = iris.data\n", "\n", "# Predict first 5 rows\n", "preds = model.predict(X[:5])\n", "print(\"Predictions for first 5 rows:\", preds.tolist())\n", "\"\"\"\n", "\n", "with open(\"model.py\", \"w\") as f:\n", "    f.write(model_code)\n", "\n", "print(\"\u2705 model.py created\")\n", "!cat model.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(\"requirements.txt\", \"w\") as f:\n", "    f.write(\"scikit-learn\\njoblib\\n\")\n", "\n", "print(\"\u2705 requirements.txt created\")\n", "!cat requirements.txt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dockerfile = \"\"\"\\\n", "FROM python:3.9-slim\n", "\n", "WORKDIR /app\n", "\n", "# Install dependencies\n", "COPY requirements.txt .\n", "RUN pip install --no-cache-dir -r requirements.txt\n", "\n", "# Copy model + code\n", "COPY model.py .\n", "COPY iris_model.pkl .\n", "\n", "# Run the script\n", "CMD [\"python\", \"model.py\"]\n", "\"\"\"\n", "\n", "with open(\"Dockerfile\", \"w\") as f:\n", "    f.write(dockerfile)\n", "\n", "print(\"\u2705 Dockerfile created\")\n", "!cat Dockerfile"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from google.colab import files\n", "\n", "files.download(\"model.py\")\n", "files.download(\"requirements.txt\")\n", "files.download(\"Dockerfile\")\n", "files.download(\"iris_model.pkl\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 0}